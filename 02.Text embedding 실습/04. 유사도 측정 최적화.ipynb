{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import os\n",
    "import openai\n",
    "import asyncio\n",
    "from tqdm.notebook import tqdm\n",
    "from openai import AsyncOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://images.unsplash.com/photo-1517836357463-d25dfeac3438?q=80&w=2940&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\" width=\"500\" height=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프로젝트 목적 : 호텔의 fitness program에 투입될 신규 인원 선발!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize openai\n",
    "os.environ['OPENAI_API_KEY']= \"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\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"resume/Resume.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.Category.isin(['CHEF', 'FITNESS'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[10, 'Resume_str'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정보 추출하기 step 1 : 필요한 정보 명확히 정의하기\n",
    "- 우리가 원하는 후보자를 search하기 위해 필요한 정보\n",
    "- 모든 이력서에 공통적으로 확보할 수 있는 정보\n",
    "\n",
    "### 정보 추출하기 step 2 : 필요한 정보 추출을 위한 방법 구상하기\n",
    "- chat completion을 활용할 수 있기 때문에, 생각의 틀을 넓혀서 추출을 위한 최적의 방법을 생각\n",
    "- chat completion 이외에도 regex나 NER 등 다양한 방법을 활용해도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Given the following resume text, \n",
    "extract and categorize the information into the specified categories: skills, work experience in years, and summary of each project. \n",
    "Please provide the extracted information in a dictionary format with the keys as 'skills', 'work experience (years)' and 'summary.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "    Skills: Identify and list all professional skills mentioned in the resume. Each element should be a word such as 'Python' or 'CSS'\n",
    "    Work Experience (years): Total years of experience. It should be a number such as '7' or '10'. Leave it empty if there are no related information.\n",
    "    Summary : For each career should be one summarized in one sentence. \n",
    "              Each sentence should be in a format of 'Worked as <job_title> from <start_date> to <end_date>, doing <work description> and accomplishing <accomplishments>'.\n",
    "              Put in 'empty' for each blank if there are on relevant information.\n",
    "    \n",
    "Ensure that the information is accurately extracted and categorized according to the instructions. If certain information is not available or cannot be accurately determined, please indicate so appropriately.\n",
    "\n",
    "Resume Text:\n",
    "{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_completion(input_prompt, model='gpt-4-turbo-preview'):\n",
    "    client = AsyncOpenAI()\n",
    "    \n",
    "    SYSTEM_PROMPT = \"You are a smart and intelligent program that understands information inside a resume, designed to output JSON\"\n",
    "    USER_PROMPT_1 = \"\"\"Are you clear about your role?\"\"\"\n",
    "    ASSISTANT_PROMPT_1 = \"\"\"Sure, I'm ready to help you with your NER task. Please provide me with the necessary information to get started.\"\"\"\n",
    "\n",
    "    response = await client.chat.completions.create(\n",
    "        model=model,\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": USER_PROMPT_1},\n",
    "            {\"role\": \"assistant\", \"content\": ASSISTANT_PROMPT_1},\n",
    "            {\"role\": \"user\", \"content\":input_prompt}\n",
    "        ]\n",
    "        )\n",
    "    return response\n",
    "\n",
    "async def run_async(main_prompt, information):\n",
    "    tasks = [chat_completion(main_prompt.format(i)) for i in information]\n",
    "    responses = await asyncio.gather(*tasks)\n",
    "    return responses\n",
    "\n",
    "def normal_chat_completion(input_prompt, model='gpt-4-turbo-preview'):\n",
    "    client = openai.OpenAI()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": 'You are a smart and intelligent program that understands information and provides output in JSON format'},\n",
    "            {\"role\": \"user\", \"content\":input_prompt}\n",
    "        ]\n",
    "        )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "async (13분 이내)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with async : 15개당 40~50초\n",
    "- without async : 15개당 ~180초 (1개당 ~12초)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [df.Resume_str[i : i+15].values.tolist() for i in range(0, len(df.Resume_str), 15)]\n",
    "outputs = list()\n",
    "\n",
    "for batch in tqdm(batches):\n",
    "    output = await run_async(prompt, batch)\n",
    "    outputs.extend(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_info = [i.choices[0].message.content for i in outputs]\n",
    "extracted_info = [json.loads(i) for i in extracted_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,info in enumerate(extracted_info):\n",
    "#     extracted_info[i]['ID'] = str(df.loc[i, 'ID'])\n",
    "#     extracted_info[i]['title'] = df.loc[i, 'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"resume/resume_info_extracted.json\", 'w') as file:\n",
    "#     json.dump(extracted_info, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resume/resume_info_extracted.json\", 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert into embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_data = list()\n",
    "\n",
    "for d in tqdm(data):\n",
    "    emb_d = dict()\n",
    "    for k, v in d.items():\n",
    "        if k in ['skills', 'summary', 'title']:\n",
    "            emb_ = create_embeddings(v) # list를 한 번에 embedding화\n",
    "            emb_d[k] = emb_\n",
    "        elif k in ['work experience (years)', 'ID']:\n",
    "            emb_d[k] = v\n",
    "        else:\n",
    "            assert False, \"Incorrect key\"\n",
    "    emb_data.append(emb_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"resume/resume_info_extracted_emb.json\", 'w') as file:\n",
    "#     json.dump(emb_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resume/resume_info_extracted_emb.json\", 'r') as file:\n",
    "    emb_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- skill\n",
    "    - threshold를 정해서, 가장 유사하다고 판단이 되는 것을 가져온다. 유사도의 평균 또는 몇 개 일치하는지\n",
    "- summary of project\n",
    "    - 어떤 프로젝트를 했는지, description을 기준으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {'skills':['Flexibility Training', 'Nutrition', 'Anatomy', 'Strength Training'],\n",
    "              'summary':\"Extensive experience in designing and implementing personalized training programs for muscle growth, with a proven track record of helping clients achieve their fitness goals\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "emb_df = pd.DataFrame(emb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_cosine_similarity(list1, list2, threshold):\n",
    "    # sklearn의 cosine_similarity 함수를 사용하여 코사인 유사도 계산\n",
    "    similarities = cosine_similarity(list1, list2)\n",
    "    columns_over_threshold = (similarities > threshold).any(axis=0)\n",
    "    \n",
    "    count = columns_over_threshold.sum() # list2를 기준으로 한 개라도 threshold를 넘는 값이 있으면 +1\n",
    "    column_indices = np.where(columns_over_threshold)[0]\n",
    "\n",
    "    return column_indices, count\n",
    "\n",
    "def candidate_search(input_list, nested_lists, top_k, search_type='skill', threshold=0.5):\n",
    "    \"\"\"\n",
    "    score : 0-1 사이의 값. 높을 수록 더 많은 match. Match의 max는 nested_list의 개수와 동일\n",
    "    현재 input으로 제공된 embedding 값과, nested_lists에 있는 element들의 embedding 값들의 cosine similarity를 계산\n",
    "    \"\"\"\n",
    "    if search_type in ['experience', 'skill']:\n",
    "        pass\n",
    "    else:\n",
    "        assert False, \"Unsupported search type\"\n",
    "\n",
    "    scores = list()\n",
    "    \n",
    "    for i, nested_list in enumerate(nested_lists):\n",
    "        # input_list와 nested_lists를 대상으로 cosine similarity를 계산, 각 element 별로 cos_sim이 threshold를 넘는 값들만 가져옴\n",
    "        _, common_elements_count = batch_cosine_similarity(input_list, nested_list, threshold)\n",
    "        # print(common_elements_count)\n",
    "        # 정규화를 위해 nested_list의 길이 계산\n",
    "        possible_matches = len(nested_list)\n",
    "        # 점수 계산 (common_elements_count / possible_matches)\n",
    "        score = common_elements_count / possible_matches if possible_matches > 0 else 0\n",
    "        scores.append((i, score))\n",
    "    \n",
    "    top_scores = sorted(scores, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    return top_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### skill based search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = emb_df['skills'].values.tolist()\n",
    "input = create_embeddings(input_dict['skills'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict['skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_based_findings = candidate_search(input, db, 10, threshold=0.5)\n",
    "skill_based_findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### summary based search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_db = emb_df['summary'].values.tolist()\n",
    "input = create_embeddings(input_dict['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_based_findings = candidate_search(input, summary_db, 10, 'experience')\n",
    "summary_based_findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[29, 'summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[34, 'summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그렇다면 Input parsing은?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 정형화된 input field\n",
    "```python\n",
    "input_dict = {'skills':['Flexibility Training', 'Nutrition', 'Anatomy', 'Strength Training'],\n",
    "              'summary':\"Extensive experience in designing and implementing personalized training programs for muscle growth, with a proven track record of helping clients achieve their fitness goals\"}\n",
    "```\n",
    "\n",
    "#### 2. 비정형 input field (free text)\n",
    "```python\n",
    "???\n",
    "```\n",
    "    - step 1 : Input을 분석하여 search를 trigger하는 layer\n",
    "    - step 2 : 요구사항을 분석하여 필요한 skill과 경험을 생성해주는 layer\n",
    "    - step 3 : search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 : trigger layer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_req = \"I want to grow muscle mass considering nutrient intake as well as various muscle training drills.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_search_queries = [\"Improving physical fitness through a combination of general physical education activities, balanced exercise routines, and nutritional awareness.\",\n",
    "                      \"Enhancing overall health with a mix of diverse physical education exercises, targeted workouts, and mindful eating habits.\",\n",
    "                      \"Increasing muscle volume by integrating nutritional strategies with multifaceted workout routines.\",\n",
    "                      \"Building muscle density by focusing on nutrient-rich diets and comprehensive resistance training programs.\",\n",
    "                      \"Streamlining trainer scheduling and client management to optimize the efficiency and effectiveness of a fitness facility.\",\n",
    "                      \"Implementing cutting-edge fitness technology and equipment maintenance protocols to ensure a state-of-the-art workout environment.\",\n",
    "                      \"Developing comprehensive staff training programs to elevate the expertise and service quality of personal trainers and fitness instructors.\",\n",
    "                      \"Enforcing health and safety standards to provide a secure and hygienic environment for members and staff alike.\",\n",
    "                      \"Cultivating a community-focused atmosphere through member engagement initiatives and personalized fitness guidance to enhance client retention and satisfaction.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_search_query_embs = create_embeddings(job_search_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_emb = create_embeddings(input_dict['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_selection(query_emb, emb_list, threshold=0.5):\n",
    "    cos_sim = cosine_similarity(query_emb, emb_list)\n",
    "\n",
    "    threshold_check = cos_sim > threshold\n",
    "\n",
    "    if threshold_check.sum()>0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_selection(input_emb, job_search_query_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 : 요구 사항을 분석하여 skill과 경력을 생성하는 layer (input dataset 생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Analyze the provided task description to identify and categorize the essential qualifications and expertise required for the job. \n",
    "The analysis should focus on extracting relevant skills and summarizing the job capabilities necessary for achieving the specified goal.\n",
    "Organize this information into a structured dictionary format.\n",
    "\n",
    "Categories: Skills and Summary.\n",
    "\n",
    "Instructions:\n",
    "- Skills: Enumerate the critical skills necessary for someone to effectively fulfill the job requirements. These should be simple words such as 'Anatomy' or 'Strength Training'\n",
    "- Summary: Draft a concise job description that encapsulates the professional experience and competencies needed to successfully execute the job responsibilities. \n",
    "            One example would be : \"Extensive experience in designing and implementing personalized training programs for muscle growth, with a proven track record of helping clients achieve their fitness goals\"\n",
    "\n",
    "Please provide the extracted information in a dictionary format with the keys as 'skills' and 'summary'.\n",
    "\n",
    "Task description:\n",
    "{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = normal_chat_completion(prompt.format(job_req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(output.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 : Search!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--END--"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
